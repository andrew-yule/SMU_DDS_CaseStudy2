---
title: "Predicting Employee Attrition"
subtitle: "An Analysis of Key Factors Leading to Employee Turnover"
author: "Andrew Yule"
format: html
editor_options: 
  chunk_output_type: console
---
## Introduction
The specific goals of this analysis are to:  

1.  Identify the top three factors that contribute to attrition  

2.  Learn about any job role specific trends that may exist in the data set (e.g., “Data Scientists have the highest job satisfaction”).  

3.  Provide any other interesting trends and observations from your analysis.  

4.  Build a model to predict attrition and salaries

## Executive Summary
To be filled in

## Libraries and Data Loading
```{r}
#| echo: true
#| output: false
#| warning: false
#| error: false
#| message: false
library(tidyverse)
library(gridExtra)
library(broom)
library(class)
library(caret)
library(e1071)

theme_set(theme_bw())
```

```{r}
#| echo: true
#| output: false
#| warning: false
#| error: false
#| message: false
employeeData = read_csv("https://raw.githubusercontent.com/ayule89/SMU_DDS_CaseStudy2/main/Data/CaseStudy2-data.csv")
```

## 1. Identifying the top three factors that contribute to attrition

#### How many of the 870 employees in the data actually left?  
There were 140 out of 870 employees (16%) that left.
```{r}
#| echo: true
#| output: true
#| warning: false
#| error: false
#| message: false
employeeData |> count(Attrition)
```

### Screening all variables to visually investigate which parameters are the highest indicators of attrition  
There are a number of variables that could attribute to employee attrition. We will first visually screen each of the variables to look for potential leading indicators. The full list of variables includes:
```{r}
#| echo: true
#| output: true
#| warning: false
#| error: false
#| message: false
colnames(employeeData)
```

Before investigating attrition across each variable, some of the numerical scales will need to put into various bins to make analysis easier. In order to determine appropriate bins, we'll first plot histograms of the numerical variables, which include: Age, DailyRate, DistanceFromHome, HourlyRate, MonthlyIncome, MonthlyRate, TotalWorkingYears, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, YearsWithCurrManager.
```{r}
#| echo: true
#| output: true
#| warning: false
#| error: false
#| message: false
employeeData |>
  select(Age, DailyRate, DistanceFromHome, HourlyRate, MonthlyIncome, MonthlyRate, TotalWorkingYears, YearsAtCompany, YearsInCurrentRole, YearsSinceLastPromotion, YearsWithCurrManager) |>
  pivot_longer(cols = everything(), names_to = "column", values_to = "value") |>
  ggplot(aes(x = value)) +
  geom_histogram() +
  facet_wrap(~column, scales = 'free', ncol = 3)
```

Based on visually inspecting the histograms, the following bins for various numerical variables will be used below. In addition, we'll change the Attrition values from strings to doubles with Yes/No being 1/0 respectively.

- Age (5 years)  
- Daily rate (400 dollars)  
- Distance from home (5 miles)  
- Hourly rate (20 dollars)  
- Monthly income (5,000 dollars)  
- Monthly rate (5,000 dollars)
- Total working years (5 years)  
- Years at company (5 years)  
- Years in current role (5 years)  
- Years since last promotion (5 years)  
- Years under current manager (5 years)

```{r}
#| echo: true
#| output: true
#| warning: false
#| error: false
#| message: false
employeeDataBinned = employeeData |>
  mutate(
    Age = round(Age/5)*5, 
    DailyRate = round(DailyRate/400)*400,
    DistanceFromHome = round(DistanceFromHome/5)*5,
    HourlyRate = round(HourlyRate/20)*20,
    MonthlyIncome = round(MonthlyIncome/5000)*5000,
    MonthlyRate = round(MonthlyRate/5000)*5000,
    TotalWorkingYears = round(TotalWorkingYears/5)*5,
    YearsAtCompany = round(YearsAtCompany/5)*5,
    YearsInCurrentRole = round(YearsInCurrentRole/5)*5,
    YearsSinceLastPromotion = round(YearsSinceLastPromotion/5)*5,
    YearsWithCurrManager = round(YearsWithCurrManager/5)*5,
    Attrition = ifelse(Attrition == "Yes", 1, 0))
```

Now we'll go through and create plots of each variable showing the breakdown between attrition to visually look for any strong relationships
```{r}
#| echo: true
#| output: true
#| warning: false
#| error: false
#| message: false
#| fig-width: 12
#| fig-height: 15
# Helper function that creates a plot showing the breakdown in attrition for a given variable across it's possible values
findAttritionBreakdown = function(df, colName) {
  df |>
    group_by(!!sym(colName)) |>
    count(Attrition) |>
    ungroup() |>
    ggplot(aes(x = !!sym(colName), y = n, fill = Attrition)) +
    geom_col(position = "fill") +
    coord_cartesian(ylim = c(0, 0.55))
}
# Test the function
findAttritionBreakdown(employeeDataBinned, "DistanceFromHome")

cols = colnames(employeeData)
# Drop columns that we don't want to include in the analysis (ID, Attrition, EmployeeCount, EmployeeNumber, Over18, StandardHours) 
cols = cols[c(-1, -3, -10, -11, -23, -28)]

# Create a list of plots across all of the columns using the map function from the purr package
plots = map(cols, function(col) findAttritionBreakdown(employeeDataBinned, col))
# Display plots on one page
grid.arrange(grobs = plots, ncol = 3)
```

Based on examining the plots above, the following key variables were identified as likely having higher impacts on employee attrition:

- Age  
- BusinessTravel  
- DistanceFromHome  
- Education  
- EnvironmentSatisfaction  
- JobInvolvment  
- JobRole  
- JobSatisfaction  
- MaritalStatus  
- MonthlyIncome  
- NumCompaniesWorked  
- OverTime  
- StockOptionLevel  
- TotalWorkingYears  
- WorkLifeBalance  
- YearsWithCurrManager  

In order to determine the top 3 factors quantitatively, we will calculate the Pseudo-R2 value for each predictor. This is based on a similar analysis that can be found [here](https://heap.io/blog/pseudo-r2-a-metric-for-quantifying-interestingness).

The main idea is that we first start with a Null model, or a baseline model, that can be used to determine the likelihood of attrition. Once that is established, then additional factors can be evaluated against this Null model using their likelihood to look for improvements or increases in the likelihood. In this case, because the likelihoods can be quite large, loglikelihood values will be used.

The Null model in this case will simply be the LogLikelihood of attrition in the entire data set or XX
```{r}
#| echo: true
#| output: true
#| warning: false
#| error: false
#| message: false
calcLogLikelihoodData = function(data){
  no = select(filter(data, Attrition == 0), n)
  yes = select(filter(data, Attrition == 1), n)
  if(dim(yes)[1] == 0 || dim(no)[1] == 0) {
    return(tibble(n = c(0)))
  }
  else{
    p = yes/(yes + no)
    log(p^yes * (1-p)^no)  
  }
}

nullModel = calcLogLikelihoodData(count(employeeDataBinned, Attrition))

calcPseudoRSquared = function(var){
  employeeDataBinned |>
    group_by(!!sym(var)) |>
    count(Attrition) |>
    group_modify(function(group, blah) calcLogLikelihoodData(select(group, Attrition, n))) |>
    ungroup() |>
    select(n) |>
    sum() |>
    (function(ll) (1-ll/nullModel$n)*100)()
}
#Test
calcPseudoRSquared("Age")

# Calculate Pseudo-R2 for all variables
pseudoRSquared = tibble("Variable" = cols) |>
  rowwise() |>
  mutate(PseudoRSquared = calcPseudoRSquared(Variable))

pseudoRSquared |>
  ggplot(aes(x = PseudoRSquared, y = fct_reorder(Variable, PseudoRSquared))) +
  geom_col() +
  labs(x = "Pseudo-RSquared", y = NULL, title = "Pseudo-RSquared Values for Each Variable")
```

Based on the analysis above, the top 3 factors influencing employee attrition are:

1. Job Role  
2. Stock Option Level  
3. Over Time



In order to quantitatively determine the top 3 variables influencing attrition, we'll build a logistic regression model using the variables above. Before using the results of that regression to determine top variables influencing attrition, we'll first use cross validation to determine the type of accuracy that can be achieved using logistic regression.
```{r}
#| echo: true
#| output: true
#| warning: false
#| error: false
#| message: false

# Train a generalized linear model using a binomial family to perform logistic regression
set.seed(1234)
model = train(Attrition ~ Age + BusinessTravel + DistanceFromHome + DistanceFromHome + Education + EnvironmentSatisfaction + JobInvolvement + JobRole + JobSatisfaction + MaritalStatus + MonthlyIncome + NumCompaniesWorked + OverTime + StockOptionLevel + TotalWorkingYears + WorkLifeBalance + YearsWithCurrManager, data = employeeData, method = "glm", family = "binomial", trControl = trainControl(method = "LOOCV"))

# Summarize the results to determine the possible accuracy
model
```

Using cross validation on our logistic regression, we can achieve an accuracy of over 88% which is high enough to warrant further use of the model to determine key variables influencing attrition.
```{r}
#| echo: true
#| output: true
#| warning: false
#| error: false
#| message: false
# Change Attrition (no/yes) into numerical values to work within the glm function
employeeDataForLogisticRegression = employeeData |>
  mutate(Attrition = ifelse(Attrition == "No", 0, 1))

# Fit the logistic regression model
model = glm(Attrition ~ Age + BusinessTravel + DistanceFromHome + DistanceFromHome + Education + EnvironmentSatisfaction + JobInvolvement + JobRole + JobSatisfaction + MaritalStatus + MonthlyIncome + NumCompaniesWorked + OverTime + StockOptionLevel + TotalWorkingYears + WorkLifeBalance + YearsWithCurrManager, family = "binomial", data = employeeDataForLogisticRegression)

# Use the results of the model fitting along with the broom package which collects model metrics into data frames to quantitatively determine the top parameters
tidy(model) |>
  #filter(p.value < 0.2) |>
  arrange(desc(abs(estimate))) |>
  print(n = 26)
```

Based on the results from the logistic regression model, the following variables are found to be the most important when determining possible employee attrition:

1. Job role
  - Most notably sales representative positions see very high attrition, while research and manufacturing directories typically have very little attrition  
2. Over time
  - Employees that work overtime are much more likely to have attrition than those that do not  
3. Marital status
  - Single employees are much more likely to have attrition than those that are married and even more so than those that are divorced  

Additional notable variables included:  

1. Business travel
  - Regular travel was highly correlated with higher attrition  
2. Job involvement
  - Low job involvement was highly correlated with higher attrition  
3. Work life balance
  - Lower work life balance was highly correlated with higher attrition

## 2. Learn about any job role specific trends that may exist in the data set

Looking closer at various job roles, it is clear that sales and HR type positions see large amounts of turnover while managing and director type roles see very little.
```{r}
#| echo: true
#| output: true
#| warning: false
#| error: false
#| message: false
employeeData |>
  group_by(JobRole) |>
  summarize(AttritionPct = 100*sum(ifelse(Attrition == "No", 0, 1))/n()) |>
  ggplot(aes(x = AttritionPct, y = reorder(JobRole, AttritionPct))) +
  geom_col() +
  labs(title = "Attrition Percentage Across Various Job Roles", x = "Attrition Percentage", y = NULL)
```

Let's investigate a little closer to see why sales / HR may have high attrition while managing / directing roles have low attrition
```{r}
#| echo: true
#| output: true
#| warning: false
#| error: false
#| message: false

# Check whether sales / HR make less money compared to the average and whether managers / directors make more compared to the average
ggplot() +
  stat_ecdf(
    data = employeeData, 
    aes(x = MonthlyIncome), color = "black") +
  stat_ecdf(
    data = filter(employeeData, JobRole == "Sales Representative"), 
    aes(x = MonthlyIncome), color = "red") +
  stat_ecdf(
    data = filter(employeeData, JobRole == "Human Resources"), 
    aes(x = MonthlyIncome), color = "Orange") +
  stat_ecdf(
    data = filter(employeeData, JobRole == "Manufacturing Director"), 
    aes(x = MonthlyIncome), color = "purple") +
  stat_ecdf(
    data = filter(employeeData, JobRole == "Research Director"), 
    aes(x = MonthlyIncome), color = "blue")
```

```{r}
set.seed(1234)
model = train(Attrition ~ MonthlyIncome, data = employeeData, method = "glm", family = "binomial", trControl = trainControl(method = "LOOCV"))

# Summarize the results to determine the possible accuracy
model
```







